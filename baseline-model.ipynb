{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10bee8d0",
   "metadata": {},
   "source": [
    "# Baseline model for spam detection & evasion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4edea6",
   "metadata": {},
   "source": [
    "### Importing libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d0544f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af8d098",
   "metadata": {},
   "source": [
    "### Loading and understanding datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5563f3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load function, will be used for each dataset\n",
    "def load_dataset(dataset_name, base_path=\"dataset\"):\n",
    "    # Adjust file names based on dataset\n",
    "    if dataset_name in [\"enron1\", \"enron2\"]:\n",
    "        train_file = f\"{dataset_name}_train.csv\"\n",
    "        test_file = f\"{dataset_name}_test.csv\"\n",
    "        val_file = f\"{dataset_name}_val.csv\"\n",
    "    else:  # For sms\n",
    "        train_file = \"train.csv\"\n",
    "        test_file = \"test.csv\"\n",
    "        val_file = \"val.csv\"\n",
    "\n",
    "    train_path = os.path.join(base_path, dataset_name, train_file)\n",
    "    test_path = os.path.join(base_path, dataset_name, test_file)\n",
    "    val_path = os.path.join(base_path, dataset_name, val_file)\n",
    "    \n",
    "    # Load the CSV files\n",
    "    train_df = pd.read_csv(train_path)\n",
    "    test_df = pd.read_csv(test_path)\n",
    "    val_df = pd.read_csv(val_path)\n",
    "    \n",
    "    # Rename columns to match expected names\n",
    "    train_df = train_df.rename(columns={'email': 'text', 'target': 'label'})\n",
    "    test_df = test_df.rename(columns={'email': 'text', 'target': 'label'})\n",
    "    val_df = val_df.rename(columns={'email': 'text', 'target': 'label'})\n",
    "\n",
    "    # Encode the labels (e.g., 'spam' → 1, 'ham' → 0)\n",
    "    le = LabelEncoder()\n",
    "    train_df['label'] = le.fit_transform(train_df['label'])\n",
    "    test_df['label'] = le.transform(test_df['label'])\n",
    "    val_df['label'] = le.transform(val_df['label'])\n",
    "\n",
    "    return train_df, test_df, val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4a11716",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['enron1', 'enron2', 'sms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9f17f15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# exploring the datasets\n",
    "def explore_dataset(dataset_name, train_df, test_df, val_df):\n",
    "    print(f\"\\n=== Exploring {dataset_name} Dataset ===\")\n",
    "    \n",
    "    # Display basic info for each split\n",
    "    print(\"\\nTrain Split:\")\n",
    "    print(f\"Number of rows: {train_df.shape[0]}\")\n",
    "    print(f\"Columns: {list(train_df.columns)}\")\n",
    "    print(\"Data types:\")\n",
    "    print(train_df.dtypes)\n",
    "    \n",
    "    print(\"\\nTest Split:\")\n",
    "    print(f\"Number of rows: {test_df.shape[0]}\")\n",
    "    print(f\"Columns: {list(test_df.columns)}\")\n",
    "    print(\"Data types:\")\n",
    "    print(test_df.dtypes)\n",
    "    \n",
    "    print(\"\\nValidation Split:\")\n",
    "    print(f\"Number of rows: {val_df.shape[0]}\")\n",
    "    print(f\"Columns: {list(val_df.columns)}\")\n",
    "    print(\"Data types:\")\n",
    "    print(val_df.dtypes)\n",
    "    \n",
    "    # Add label distribution\n",
    "    print(\"\\nLabel Distribution:\")\n",
    "    for split_name, df in [(\"Train\", train_df), (\"Test\", test_df), (\"Validation\", val_df)]:\n",
    "        print(f\"\\n{split_name} Split:\")\n",
    "        label_counts = df['label'].value_counts()\n",
    "        print(label_counts)\n",
    "        print(f\"Spam percentage: {100 * label_counts.get(1, 0) / len(df):.2f}%\")\n",
    "    \n",
    "    # Add sample rows\n",
    "    print(\"\\nSample Rows from Train Split:\")\n",
    "    print(train_df.head())\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "00679797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing enron1 dataset...\n",
      "\n",
      "=== Exploring enron1 Dataset ===\n",
      "\n",
      "Train Split:\n",
      "Number of rows: 3196\n",
      "Columns: ['text', 'label']\n",
      "Data types:\n",
      "text     object\n",
      "label     int64\n",
      "dtype: object\n",
      "\n",
      "Test Split:\n",
      "Number of rows: 999\n",
      "Columns: ['text', 'label']\n",
      "Data types:\n",
      "text     object\n",
      "label     int64\n",
      "dtype: object\n",
      "\n",
      "Validation Split:\n",
      "Number of rows: 799\n",
      "Columns: ['text', 'label']\n",
      "Data types:\n",
      "text     object\n",
      "label     int64\n",
      "dtype: object\n",
      "\n",
      "Label Distribution:\n",
      "\n",
      "Train Split:\n",
      "label\n",
      "0    2260\n",
      "1     936\n",
      "Name: count, dtype: int64\n",
      "Spam percentage: 29.29%\n",
      "\n",
      "Test Split:\n",
      "label\n",
      "0    706\n",
      "1    293\n",
      "Name: count, dtype: int64\n",
      "Spam percentage: 29.33%\n",
      "\n",
      "Validation Split:\n",
      "label\n",
      "0    565\n",
      "1    234\n",
      "Name: count, dtype: int64\n",
      "Spam percentage: 29.29%\n",
      "\n",
      "Sample Rows from Train Split:\n",
      "                                                text  label\n",
      "0  Subject: prom dress shopping hi , just wanted ...      0\n",
      "1  Subject: hi agaain hello , welcome to pharm la...      1\n",
      "2  Subject: feedback monitor error - meter 984132...      0\n",
      "3  Subject: instructions to remove spyware / adwa...      1\n",
      "4  Subject: acrobat pro 7 . 0 $ 69 . 95 xp pro op...      1\n",
      "\n",
      "Processing enron2 dataset...\n",
      "\n",
      "=== Exploring enron2 Dataset ===\n",
      "\n",
      "Train Split:\n",
      "Number of rows: 3727\n",
      "Columns: ['text', 'label']\n",
      "Data types:\n",
      "text     object\n",
      "label     int64\n",
      "dtype: object\n",
      "\n",
      "Test Split:\n",
      "Number of rows: 1165\n",
      "Columns: ['text', 'label']\n",
      "Data types:\n",
      "text     object\n",
      "label     int64\n",
      "dtype: object\n",
      "\n",
      "Validation Split:\n",
      "Number of rows: 932\n",
      "Columns: ['text', 'label']\n",
      "Data types:\n",
      "text     object\n",
      "label     int64\n",
      "dtype: object\n",
      "\n",
      "Label Distribution:\n",
      "\n",
      "Train Split:\n",
      "label\n",
      "0    2769\n",
      "1     958\n",
      "Name: count, dtype: int64\n",
      "Spam percentage: 25.70%\n",
      "\n",
      "Test Split:\n",
      "label\n",
      "0    866\n",
      "1    299\n",
      "Name: count, dtype: int64\n",
      "Spam percentage: 25.67%\n",
      "\n",
      "Validation Split:\n",
      "label\n",
      "0    693\n",
      "1    239\n",
      "Name: count, dtype: int64\n",
      "Spam percentage: 25.64%\n",
      "\n",
      "Sample Rows from Train Split:\n",
      "                                                text  label\n",
      "0  Subject: membership in the nsf vince : karen m...      0\n",
      "1  Subject: holiday gift thank you so much for yo...      0\n",
      "2  Subject: re : real options vince , if you take...      0\n",
      "3  Subject: men charset = windows - 1252 \" > vigo...      1\n",
      "4  Subject: vaal medz how t pestilent o save on y...      1\n",
      "\n",
      "Processing sms dataset...\n",
      "\n",
      "=== Exploring sms Dataset ===\n",
      "\n",
      "Train Split:\n",
      "Number of rows: 3565\n",
      "Columns: ['text', 'label']\n",
      "Data types:\n",
      "text     object\n",
      "label     int64\n",
      "dtype: object\n",
      "\n",
      "Test Split:\n",
      "Number of rows: 1115\n",
      "Columns: ['text', 'label']\n",
      "Data types:\n",
      "text     object\n",
      "label     int64\n",
      "dtype: object\n",
      "\n",
      "Validation Split:\n",
      "Number of rows: 892\n",
      "Columns: ['text', 'label']\n",
      "Data types:\n",
      "text     object\n",
      "label     int64\n",
      "dtype: object\n",
      "\n",
      "Label Distribution:\n",
      "\n",
      "Train Split:\n",
      "label\n",
      "0    3087\n",
      "1     478\n",
      "Name: count, dtype: int64\n",
      "Spam percentage: 13.41%\n",
      "\n",
      "Test Split:\n",
      "label\n",
      "0    966\n",
      "1    149\n",
      "Name: count, dtype: int64\n",
      "Spam percentage: 13.36%\n",
      "\n",
      "Validation Split:\n",
      "label\n",
      "0    772\n",
      "1    120\n",
      "Name: count, dtype: int64\n",
      "Spam percentage: 13.45%\n",
      "\n",
      "Sample Rows from Train Split:\n",
      "                                                text  label\n",
      "0  What to think no one saying clearly. Ok leave ...      0\n",
      "1  FREE RING TONE just text \\POLYS\\\" to 87131. Th...      1\n",
      "2          Trust me. Even if isn't there, its there.      0\n",
      "3  Hi dear we saw dear. We both are happy. Where ...      0\n",
      "4  URGENT, IMPORTANT INFORMATION FOR O2 USER. TOD...      1\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets:\n",
    "    print(f\"\\nProcessing {dataset} dataset...\")\n",
    "    train_df, test_df, val_df = load_dataset(dataset)\n",
    "    explore_dataset(dataset, train_df, test_df, val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e12f6d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data and extract TF-IDF features\n",
    "def prepare_data(train_df, test_df, val_df):\n",
    "    X_train = train_df['text'].values\n",
    "    y_train = train_df['label'].values\n",
    "    X_test = test_df['text'].values\n",
    "    y_test = test_df['label'].values\n",
    "    X_val = val_df['text'].values\n",
    "    y_val = val_df['label'].values\n",
    "\n",
    "    # Convert text to TF-IDF features\n",
    "    vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')\n",
    "    X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "    X_test_tfidf = vectorizer.transform(X_test)\n",
    "    X_val_tfidf = vectorizer.transform(X_val)\n",
    "\n",
    "    return X_train_tfidf, y_train, X_test_tfidf, y_test, X_val_tfidf, y_val, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c35a103e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate a classifier (Naïve Bayes or Logistic Regression)\n",
    "def train_and_evaluate(classifier, classifier_name, X_train, y_train, X_test, y_test, dataset_name):\n",
    "    # Train the classifier\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='binary')\n",
    "    recall = recall_score(y_test, y_pred, average='binary')\n",
    "    f1 = f1_score(y_test, y_pred, average='binary')\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"\\nResults for {dataset_name} dataset ({classifier_name}):\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-Score: {f1:.4f}\")\n",
    "    print(\"\\nDetailed Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=['ham', 'spam']))\n",
    "\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "598948b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing enron1 dataset...\n",
      "\n",
      "Results for enron1 dataset (Naïve Bayes):\n",
      "Accuracy: 0.9600\n",
      "Precision: 0.9408\n",
      "Recall: 0.9215\n",
      "F1-Score: 0.9310\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      0.98      0.97       706\n",
      "        spam       0.94      0.92      0.93       293\n",
      "\n",
      "    accuracy                           0.96       999\n",
      "   macro avg       0.95      0.95      0.95       999\n",
      "weighted avg       0.96      0.96      0.96       999\n",
      "\n",
      "\n",
      "Results for enron1 dataset (Logistic Regression):\n",
      "Accuracy: 0.9770\n",
      "Precision: 0.9327\n",
      "Recall: 0.9932\n",
      "F1-Score: 0.9620\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       1.00      0.97      0.98       706\n",
      "        spam       0.93      0.99      0.96       293\n",
      "\n",
      "    accuracy                           0.98       999\n",
      "   macro avg       0.96      0.98      0.97       999\n",
      "weighted avg       0.98      0.98      0.98       999\n",
      "\n",
      "\n",
      "Processing enron2 dataset...\n",
      "\n",
      "Results for enron2 dataset (Naïve Bayes):\n",
      "Accuracy: 0.9820\n",
      "Precision: 0.9929\n",
      "Recall: 0.9365\n",
      "F1-Score: 0.9639\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      1.00      0.99       866\n",
      "        spam       0.99      0.94      0.96       299\n",
      "\n",
      "    accuracy                           0.98      1165\n",
      "   macro avg       0.99      0.97      0.98      1165\n",
      "weighted avg       0.98      0.98      0.98      1165\n",
      "\n",
      "\n",
      "Results for enron2 dataset (Logistic Regression):\n",
      "Accuracy: 0.9871\n",
      "Precision: 0.9581\n",
      "Recall: 0.9933\n",
      "F1-Score: 0.9754\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       1.00      0.98      0.99       866\n",
      "        spam       0.96      0.99      0.98       299\n",
      "\n",
      "    accuracy                           0.99      1165\n",
      "   macro avg       0.98      0.99      0.98      1165\n",
      "weighted avg       0.99      0.99      0.99      1165\n",
      "\n",
      "\n",
      "Processing sms dataset...\n",
      "\n",
      "Results for sms dataset (Naïve Bayes):\n",
      "Accuracy: 0.9695\n",
      "Precision: 1.0000\n",
      "Recall: 0.7718\n",
      "F1-Score: 0.8712\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      1.00      0.98       966\n",
      "        spam       1.00      0.77      0.87       149\n",
      "\n",
      "    accuracy                           0.97      1115\n",
      "   macro avg       0.98      0.89      0.93      1115\n",
      "weighted avg       0.97      0.97      0.97      1115\n",
      "\n",
      "\n",
      "Results for sms dataset (Logistic Regression):\n",
      "Accuracy: 0.9821\n",
      "Precision: 0.9448\n",
      "Recall: 0.9195\n",
      "F1-Score: 0.9320\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      0.99      0.99       966\n",
      "        spam       0.94      0.92      0.93       149\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.97      0.96      0.96      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets:\n",
    "        print(f\"\\nProcessing {dataset} dataset...\")\n",
    "        \n",
    "        # Load the data\n",
    "        train_df, test_df, val_df = load_dataset(dataset)\n",
    "        \n",
    "        # Prepare the data (TF-IDF features)\n",
    "        X_train_tfidf, y_train, X_test_tfidf, y_test, X_val_tfidf, y_val, vectorizer = prepare_data(train_df, test_df, val_df)\n",
    "        \n",
    "        # Train and evaluate Naïve Bayes\n",
    "        nb_classifier = MultinomialNB()\n",
    "        train_and_evaluate(nb_classifier, \"Naïve Bayes\", X_train_tfidf, y_train, X_test_tfidf, y_test, dataset)\n",
    "        \n",
    "        # Train and evaluate Logistic Regression\n",
    "        lr_classifier = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "        train_and_evaluate(lr_classifier, \"Logistic Regression\", X_train_tfidf, y_train, X_test_tfidf, y_test, dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
